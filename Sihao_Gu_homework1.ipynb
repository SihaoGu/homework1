{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE 258, Fall 2018: Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Task - Regression\n",
    "import numpy\n",
    "import urllib.request\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(parseDataFromFile(\"beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the distribution of ratings in the dataset (for `review/taste')? That is, how many 1-star, 2-star, 3-star (etc.) reviews are there? You may write out the values or include a simple plot (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_taste = []\n",
    "for i in range(0, len(data)):\n",
    "    review_taste.append(data[i]['review/taste'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = numpy.unique(review_taste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_taste1 = review_taste.count(1.0)\n",
    "review_taste2 = review_taste.count(1.5)\n",
    "review_taste3 = review_taste.count(2.0)\n",
    "review_taste4 = review_taste.count(2.5)\n",
    "review_taste5 = review_taste.count(3.0)\n",
    "review_taste6 = review_taste.count(3.5)\n",
    "review_taste7 = review_taste.count(4.0)\n",
    "review_taste8 = review_taste.count(4.5)\n",
    "review_taste9 = review_taste.count(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "343\n",
      "1099\n",
      "1624\n",
      "4137\n",
      "8797\n",
      "16575\n",
      "12883\n",
      "4331\n"
     ]
    }
   ],
   "source": [
    "print(review_taste1) #count of review/taste=1.0\n",
    "print(review_taste2) #count of review/taste=1.5\n",
    "print(review_taste3) #count of review/taste=2.0\n",
    "print(review_taste4) #count of review/taste=2.5\n",
    "print(review_taste5) #count of review/taste=3.0\n",
    "print(review_taste6) #count of review/taste=3.5\n",
    "print(review_taste7) #count of review/taste=4.0\n",
    "print(review_taste8) #count of review/taste=4.5\n",
    "print(review_taste9) #count of review/taste=5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a simple predictor to predict a beer's `taste' score using two features: review/taste ' = theta0 + theta1 * [beer is a Hefeweizen] + theta2 * beer/ABV. Report the values of theta0, theta1, and theta2. Briefly describe your interpretation of these values, i.e., what do theta0, theta1, and theta2 represent (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if datum['beer/style'] == \"Hefeweizen\":\n",
    "      feat.append(1)\n",
    "  else:\n",
    "      feat.append(0)\n",
    "  feat.append(datum['beer/ABV'])\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['review/taste'] for d in data]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11795084, -0.05637406,  0.10877902])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# theta 0 is intercept, theta 1 and theta 2 are coeffecients of whether beer is Hefeweizen and beer's ABV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data into two equal fractions - the first half for training, the second half for testing (based on the order they appear in the file). Train the same model as above on the training set only. What is the model's MSE on the training and on the test set (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:25000]\n",
    "test = data[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if datum['beer/style'] == \"Hefeweizen\":\n",
    "      feat.append(1)\n",
    "  else:\n",
    "      feat.append(0)\n",
    "  feat.append(datum['beer/ABV'])\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "y = [d['review/taste'] for d in train]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.99691466, -0.03573098,  0.11672256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_train = theta * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = []\n",
    "for i in value_train:\n",
    "    y_pred_train.append(i[0] + i[1] + i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4839680560134243"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE on train set\n",
    "mean_squared_error(y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [d['review/taste'] for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [feature(d) for d in test]\n",
    "value_test =theta * X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = []\n",
    "for i in value_test:\n",
    "    y_pred_test.append(i[0] + i[1] + i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4237065211985418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE on test set\n",
    "mean_squared_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using the first half for training and the second half for testing may lead to unexpected results (e.g. the training error could be higher than the test error). Repeat the above experiment by using a random 50% split of the data (i.e., half for training, half for testing, after first shuffling the data). Report the MSE on the train and test set, and suggest one possible reason why the result may be different from the previous experiment (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if datum['beer/style'] == \"Hefeweizen\":\n",
    "      feat.append(1)\n",
    "  else:\n",
    "      feat.append(0)\n",
    "  feat.append(datum['beer/ABV'])\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = shuffle(data, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data_shuffle]\n",
    "y = [d['review/taste'] for d in data_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X[:25000]\n",
    "X_test = X[25000:]\n",
    "y_train = y[:25000]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = numpy.linalg.lstsq(X_train, y_train, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.09739998, -0.05149452,  0.11127861])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_train_4 = theta * X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_4 = []\n",
    "for i in value_train_4:\n",
    "    y_pred_train_4.append(i[0] + i[1] + i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45246733676565154"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE on train set\n",
    "mean_squared_error(y_train, y_pred_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_test_5 = theta * X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_5 = []\n",
    "for i in value_test_5:\n",
    "    y_pred_test_5.append(i[0] + i[1] + i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4469235257636903"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE on test set\n",
    "mean_squared_error(y_test, y_pred_test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modify your experiment from Question 4 to use the features: review/taste ' = theta0 + theta1 * [ABV if beer is a Hefeweizen] + theta2 * [ABV if beer is not a Hefeweizen]. e.g. the first beer in the dataset would have feature [1, 5.0, 0] since the beer is a Hefeweizen. Report the training and testing MSE of this method (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if datum['beer/style'] == \"Hefeweizen\":\n",
    "      feat.append(datum['beer/ABV'])\n",
    "      feat.append(0)\n",
    "  else:\n",
    "      feat.append(0)\n",
    "      feat.append(datum['beer/ABV'])\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = shuffle(data, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data_shuffle]\n",
    "y = [d['review/taste'] for d in data_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X[:25000]\n",
    "X_test = X[25000:]\n",
    "y_train = y[:25000]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = numpy.linalg.lstsq(X_train, y_train, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.09776369, 0.09988903, 0.11124353])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_train_6 = theta * X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_6 = []\n",
    "for i in value_train_6:\n",
    "    y_pred_train_6.append(i[0] + i[1] + i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45245562268694434"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE on train set\n",
    "mean_squared_error(y_train, y_pred_train_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_test_7 = theta * X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_7 = []\n",
    "for i in value_test_7:\n",
    "    y_pred_test_7.append(i[0] + i[1] + i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4469246426210711"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE on test set\n",
    "mean_squared_error(y_test, y_pred_test_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The model from Question 5 uses the same two features as the model from Questions 2-4 and has the same dimensionality. Comment on why the two models might perform differently (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer: Although Question 5 uses the same two features as the model from Questions 2-4 and has the same dimensionlity, the result of feature is different. For example, the first beer in the dataset in Questions 2-4 model is [1, 1, 5.0]. However, in Question 5 model, the feature of first beer in the dataset is [1, 5.0, 0]. Model in Questions 2-4 consider whether beer is Hefeweizen in the second position and put beer/ABV no matter which kinds of beer/style in the third position. Model in Questions 5 consider whether beer is Hefeweizne first. If yes,put corresponding beer/ABV in the second position and 0 in third position. If not, put 0 in the second position and corresponding beer/ABV in the third position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Task - Classfication\n",
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. First, let's train a predictor that estimates whether a beer is a `Hefeweizen' using five features describing its rating:['review/taste', 'review/appearance', 'review/aroma', 'review/palate', 'review/overall']. Train your predictor using an SVM classifier (see the code provided in class). Use a random split of the data as we did in Question 4. Use a regularization constant of C = 1000 as in the code stub. What is the accuracy (percentage of correct classifications) of the predictor on the train and test data? (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(datum):\n",
    "  feat = []\n",
    "  feat.append(datum['review/taste'])\n",
    "  feat.append(datum['review/appearance'])\n",
    "  feat.append(datum['review/aroma'])\n",
    "  feat.append(datum['review/palate'])\n",
    "  feat.append(datum['review/overall'])\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = shuffle(data, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [select(d) for d in data_shuffle]\n",
    "y = [d['beer/style'] == 'Hefeweizen' for d in data_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X[:25000]\n",
    "X_test = X[25000:]\n",
    "y_train = y[:25000]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the predictor on train set\n",
    "correct_train = train_predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98768"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Acc = sum(correct_train)/ len(correct_train)\n",
    "train_Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the predictor on test set\n",
    "correct_test = test_predictions == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Acc = sum(correct_test)/ len(correct_test)\n",
    "test_Acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Considering same prediction problem as above, can you come up with a more accurate predictor (e.g. using features from the text, or otherwise)? Write down the feature vector you design, and report its train/test accuracy (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(datum):\n",
    "  feat = []\n",
    "  feat.append(datum['review/taste'])\n",
    "  feat.append(datum['review/appearance'])\n",
    "  feat.append(datum['review/aroma'])\n",
    "  feat.append(datum['review/palate'])\n",
    "  feat.append(datum['review/overall'])\n",
    "  feat.append('weizen' in datum['beer/name'])\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I add whether 'weizen' in 'beer/name' in the feature vector and use the same five features in question 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = shuffle(data, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [select(d) for d in data_shuffle]\n",
    "y = [d['beer/style'] == 'Hefeweizen' for d in data_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X[:25000]\n",
    "X_test = X[25000:]\n",
    "y_train = y[:25000]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the predictor on train set\n",
    "correct_train = train_predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99172"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Acc = sum(correct_train)/ len(correct_train)\n",
    "train_Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the predictor on test set\n",
    "correct_test = test_predictions == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99188"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Acc = sum(correct_test)/ len(correct_test)\n",
    "test_Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
